---
title: "Lab 3 - MLR: Part 1"
author: "PrabhTalwar"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  '': default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(tidyverse)

teamperf <- read_csv("teamperf.csv")
```

## (a) Hypothesize a first-order model for project scores y as a function of x1, x2 and x3

Our dependent variable(y) is mean project score. Three independent variables for each team: range of intra-personal scores (x1), range of stress management (x2),and range of mood scores (x3)

## (b) Use a appropriate plots to verify a linear relationship

```{r}
ggplot(data = teamperf, mapping = aes(x = intrapersonal_range, y = project_score))+
  geom_point()+
  geom_smooth(method='lm', se = FALSE)

ggplot(data = teamperf, mapping = aes(x = stress_range, y = project_score))+
  geom_point()+
  geom_smooth(method='lm', se = FALSE)

ggplot(data = teamperf, mapping = aes(x = mood_range, y = project_score))+
  geom_point()+
  geom_smooth(method='lm', se = FALSE)
```

## (c) Fit the model in part (a), to the data using R

```{r}
model = lm(project_score ~ intrapersonal_range + stress_range + mood_range, data = teamperf)
coef(model)

```

## (d) Use matrices to verify the equations and produce the same coefficients.

```{r}
n = nrow(teamperf)
p = length(coef(model)) 

X = cbind(rep(1, n), teamperf$intrapersonal_range, teamperf$stress_range, teamperf$mood_range)
y = teamperf$project_score
beta_hat = solve(t(X) %*% X) %*% t(X) %*% y
beta_hat
```

## (e) Is there sufficient evidence to indicate the overall model is statistically useful for predicting y? Test using alpha = 0.10.


```{r}
summary(model)
```
The p-value for our model is 0.09204 which is less than 0.10, means that our model is statistically significant.


## (f) Evaluate the model using statistics R2 adjusted and 2s.

```{r}
summary(model)
2 * 3.023
```
Adjusted R-squared for our model is 0.1681.Adjusted R2 tells us the percentage of variation explained by only the independent variables that actually affect the dependent variable which is quite less in our case.
Here, We can expect 95% of the observed values of y to lie within 2s (2 standard deviations away) of y, i.e.; 6.046

## (g) Find and interpret a 95% confidence interval for y when x1 = 20, x2 = 30 and x3 = 25.

```{r}
new_team = data.frame(intrapersonal_range = 20, stress_range = 30, mood_range = 25)
new_team
```

```{r}
predict(model, newdata = new_team, interval = "confidence", level = 0.95)
```

## (h) Find and interpret a 95% prediction interval for y when x1 = 20, x2 = 30 and x3 = 25.

```{r}
new_team1 = data.frame(intrapersonal_range = 20, stress_range = 30, mood_range = 25)
new_team1
```

```{r}
predict(model, newdata = new_team1, interval = "prediction", level = 0.95)
```

